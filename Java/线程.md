### 线程安全的单例模式
+ 双重检查锁
+ 同步代码块 ，synchronized 实现方法 monitorenter monitorexit， 同步修饰的方法， 方法有flag ACC_SYNCHRONIZED标志，本质都是对monitor对象的获取
+ JDK1.6 对锁的实现引入了大量的优化，如偏向锁、轻量级锁、自旋锁、适应性自旋锁、锁消除、锁粗化等技术来减少锁操作的开销。
+ **JDK 1.5之前**，Java通过**synchronized**关键字来实现**锁**功能
synchronized是JVM实现的内置锁，锁的获取和释放都是由JVM隐式实现的
+ JDK 1.5，并发包中新增了Lock接口来实现锁功能
提供了与synchronized类似的同步功能，但需要显式获取和释放锁
+ Lock同步锁是基于Java实现的，而synchronized是基于底层操作系统的Mutex Lock实现的
每次获取和释放锁都会带来用户态和内核态的切换，从而增加系统的性能开销在锁竞争激烈的情况下，synchronized同步锁的性能很糟糕在JDK 1.5，在单线程重复申请锁的情况下，synchronized锁性能要比Lock的性能差很多
+ JDK 1.6，Java对synchronized同步锁做了充分的优化，甚至在某些场景下，它的性能已经超越了Lock同步锁
+ 无锁，偏向锁，轻量级锁，重量级锁，减少上下文切换
+ 悲观锁策略，假设每一次执行临界区代码都会产生冲突，所以当前线程获取到锁的时候同时也会阻塞其他线程获取该锁。而CAS操作是一种**乐观锁**策略，它假设所有线程访问共享资源的时候不会出现冲突，既然不会出现冲突自然而然就不会阻塞其他线程的操作。因此，线程就不会出现阻塞停顿的状态，那么这种情况下出现冲突了怎么办？无锁操作是使用CAS（compare and swap）又叫做比较交换来鉴别线程是否出现冲突，出现冲突就重试当前操作直到没有冲突为止。
### 锁的分类
- 从线程是否需要对资源加锁可以分为 悲观锁 和 乐观锁
- 从资源已被锁定，线程是否阻塞可以分为 自旋锁
- 从多个线程并发访问资源，也就是 Synchronized 可以分为 无锁、偏向锁、 轻量级锁 和 重量级锁
- 从锁的公平性进行区分，可以分为公平锁 和 非公平锁
- 从根据锁是否重复获取可以分为 可重入锁 和 不可重入锁
- 从那个多个线程能否获取同一把锁分为 共享锁 和 排他锁

### 乐观锁的实现机制
版本号， CAS（比较和交换）
CAS 中涉及三个要素：
需要读写的内存值 V，进行比较的值 A，拟写入的新值 B，当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。

#### 乐观锁的缺点
- ABA问题
ABA 问题说的是，如果一个变量第一次读取的值是 A，准备好需要对 A 进行写操作的时候，发现值还是 A，那么这种情况下，能认为 A 的值没有被改变过吗？可以是由 A -> B -> A 的这种情况，但是 AtomicInteger 却不会这么认为，它只相信它看到的，它看到的是什么就是什么。

#### 循环开销大
们知道乐观锁在进行写操作的时候会判断是否能够写入成功，如果写入不成功将触发等待 -> 重试机制，这种情况是一个自旋锁，简单来说就是适用于短期内获取不到，进行等待重试的锁，它不适用于长期获取不到锁的情况，另外，自旋循环对于性能开销比较大。

#### CAS与synchronized的使用情景
简单的来说 CAS 适用于写比较少的情况下（多读场景，冲突一般较少），synchronized 适用于写比较多的情况下（多写场景，冲突一般较多）

-   对于资源竞争较少（线程冲突较轻）的情况，使用 Synchronized 同步锁进行线程阻塞和唤醒切换以及用户态内核态间的切换操作额外浪费消耗 cpu 资源；而 CAS 基于硬件实现，不需要进入内核，不需要切换线程，操作自旋几率较少，因此可以获得更高的性能。
-   对于资源竞争严重（线程冲突严重）的情况，CAS 自旋的概率会比较大，从而浪费更多的 CPU 资源，效率低于 synchronized。

#### 自旋锁
互斥访问， 自旋锁， 互斥锁
自旋锁的原理比较简单，如果持有锁的线程能在短时间内释放锁资源，那么那些等待竞争锁的线程就不需要做内核态和用户态之间的切换进入阻塞状态，它们只需要等一等(自旋)，等到持有锁的线程释放锁之后即可获取，这样就避免了用户进程和内核切换的消耗。
如果长时间上锁的话，自旋锁会非常耗费性能
解决上面这种情况一个很好的方式是给自旋锁设定一个自旋时间，等时间一到立即释放自旋锁。

#### 自旋锁的优缺点
优点
自旋锁尽可能的减少线程的阻塞，这对于锁的竞争不激烈，且占用锁时间非常短的代码块来说性能能大幅度的提升，因为自旋的消耗会小于线程阻塞挂起再唤醒的操作的消耗，这些操作会导致线程发生两次上下文切换！

但是如果锁的竞争激烈，或者持有锁的线程需要长时间占用锁执行同步块，这时候就不适合使用自旋锁了，因为自旋锁在获取锁前一直都是占用 cpu 做无用功，占着 XX 不 XX，同时有大量线程在竞争一个锁，会导致获取锁的时间很长，线程自旋的消耗大于线程阻塞挂起操作的消耗，其它需要 cpu 的线程又不能获取到 cpu，造成 cpu 的浪费。所以这种情况下我们要关闭自旋锁。

#### 自旋锁的实现
简单的自旋锁有一个问题：**无法保证多线程竞争的公平性**。对于上面的 SpinlockTest，当多个线程想要获取锁时，谁最先将`available`设为`false`谁就能最先获得锁，这可能会造成某些线程一直都未获取到锁造成`线程饥饿`
通常我们会采取排队的方式解决这样的问题，类似地，我们把这种锁叫**排队自旋锁(QueuedSpinlock)**。计算机科学家们使用了各种方式来实现排队自旋锁，如TicketLock，MCSLock，CLHLock。

- TicketLock
TicketLock 是基于先进先出(FIFO) 队列的机制。它增加了锁的公平性，其设计原则如下：TicketLock 中有两个 int 类型的数值，开始都是0，第一个值是队列ticket(队列票据)， 第二个值是 出队(票据)。队列票据是线程在队列中的位置，而出队票据是现在持有锁的票证的队列位置。可能有点模糊不清，简单来说，就是队列票据是你取票号的位置，出队票据是你距离叫号的位置。现在应该明白一些了吧。
每次叫号机在叫号的时候，都会判断自己是不是被叫的号，并且每个人在办完业务的时候，叫号机根据在当前号码的基础上 + 1，让队列继续往前走。
- CLHLock
虚拟队列，每个线程有一个节点，节点有一个标志，标志为true时，表示需要锁或已获得锁。每个线程在其前驱线程的节点上自旋。线程结束把节点标志设为false，表示释放锁

- MCSLock
相比CLHLock，对于NUMA结构，能减少内存访问延迟，因为每个线程等待锁的时候是在自己线程的节点上自旋，当一个线程释放锁后，会通知其后继线程


### volatile解析
1. **内存模型**
- 高速缓存的多线程不一致性
如果一个变量在多个CPU中都存在缓存（一般在多线程编程时才会出现），那么就可能存在缓存不一致的问题。

    为了解决缓存不一致性问题，通常来说有以下2种解决方法：
　　1）通过在总线加LOCK#锁的方式
　　2）通过缓存一致性协议
2. **并发三个概念**
- 原子性
原子性：即一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。
- 可见性
可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。
- 有序性
有序性：即程序执行的顺序按照代码的先后顺序执行。
指令重排序不会影响单个线程的执行，但是会影响到线程并发执行的正确性。
3. **Java的内存模型**
- 原子性
　　在Java中，对基本数据类型的变量的读取和赋值操作是原子性操作，即这些操作是不可被中断的，要么执行，要么不执行。
　　Java内存模型只保证了基本读取和赋值是原子性操作，如果要实现更大范围操作的原子性，可以通过synchronized和Lock来实现。由于synchronized和Lock能够保证任一时刻只有一个线程执行该代码块，那么自然就不存在原子性问题了，从而保证了原子性。
- 可见性
　　对于可见性，Java提供了volatile关键字来保证可见性。　　当一个共享变量被volatile修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。　　
　　另外，通过synchronized和Lock也能够保证可见性
- 有序性
    在Java内存模型中，允许编译器和处理器对指令进行重排序，但是重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。
    在Java里面，可以通过volatile关键字来保证一定的“有序性”（具体原理在下一节讲述）。另外可以通过synchronized和Lock来保证有序性，很显然，synchronized和Lock保证每个时刻是有一个线程执行同步代码，相当于是让线程顺序执行同步代码，自然就保证了有序性。
    另外，Java内存模型具备一些先天的“有序性”，即不需要通过任何手段就能够得到保证的有序性，这个通常也称为 happens-before 原则。如果两个操作的执行次序无法从happens-before原则推导出来，那么它们就不能保证它们的有序性，虚拟机可以随意地对它们进行重排序。
    
4. **volatile关键字的两层语义**
- **一旦一个共享变量（类的成员变量、类的静态成员变量）被volatile修饰之后，那么就具备了两层语义：**
    1）保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。
    2）禁止进行指令重排序。
- **volatile不保证原子性，以下例子表明**
```java
public class Test {
    public volatile int inc = 0;
     
    public void increase() {
        inc++;
    }
     
    public static void main(String[] args) {
        final Test test = new Test();
        for(int i=0;i<10;i++){
            new Thread(){
                public void run() {
                    for(int j=0;j<1000;j++)
                        test.increase();
                };
            }.start();
        }
         
        while(Thread.activeCount()>1){
            Thread.yield();
        }
        System.out.println(test.inc);
    }
}
```
inc最后是一个小于10000的数。
    线程1对变量进行读取操作之后，被阻塞了的话，并没有对inc值进行修改。然后虽然volatile能保证线程2对变量inc的值读取是从内存中读取的，但是线程1没有进行修改，所以线程2根本就不会看到修改的值。两个线程分别进行了一次自增操作后，inc只增加了1。
    根源就在这里，自增操作不是原子性操作，而且volatile也无法保证对变量的任何操作都是原子性的。
    可以用三种方法解决问题，采用synchronized，采用lock，采用AtomicInteger。
    在java 1.5的java.util.concurrent.atomic包下提供了一些原子操作类，即对基本数据类型的 自增（加1操作），自减（减1操作）、以及加法操作（加一个数），减法操作（减一个数）进行了封装，保证这些操作是原子性操作。atomic是利用CAS来实现原子性操作的（Compare And Swap），CAS实际上是利用处理器提供的CMPXCHG指令实现的，而处理器执行CMPXCHG指令是一个原子性操作。
- **volatile能在一定程度上保证有序性。**
    volatile关键字禁止指令重排序有两层意思：
　　1）当程序执行到volatile变量的读操作或者写操作时，在其前面的操作的更改肯定全部已经进行，且结果已经对后面的操作可见；在其后面的操作肯定还没有进行；
　　2）在进行指令优化时，不能将在对volatile变量访问的语句放在其后面执行，也不能把volatile变量后面的语句放到其前面执行。
　　
- ** volatile原理和实现机制**
    观察加入volatile关键字和没有加入volatile关键字时所生成的汇编代码发现，加入volatile关键字时，会多出一个lock前缀指令”
    lock前缀指令实际上相当于一个内存屏障（也成内存栅栏），内存屏障会提供3个功能：
    1）它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成；
    2）它会强制将对缓存的修改操作立即写入主存；
    3）如果是写操作，它会导致其他CPU中对应的缓存行无效。
5. **使用volatile关键字的场景**
    要注意volatile关键字是无法替代synchronized关键字的，因为volatile关键字无法保证操作的原子性。通常来说，使用volatile必须具备以下2个条件：  
    1）对变量的写操作不依赖于当前值
    2）该变量没有包含在具有其他变量的不变式中
    实际上，这些条件表明，可以被写入 volatile 变量的这些有效值独立于任何程序的状态，包括变量的当前状态。


    






> Written with [StackEdit](https://stackedit.io/).
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTE2MDM0MDU0MDVdfQ==
-->